## Ship Detections on-the-fly

This indicator is community contributed. It is based on a [Machine Learning model](https://github.com/ShipDetectionExperts/draft_inference) and visualisation concept developed by: [Selim Behloul](https://github.com/Selimgit), [Juraj Zvolensky](https://github.com/jzvolensky) and [Leah Sturm](https://github.com/leahsturm) as part of a 6-month internship with the European Space Agency. 

The model uses a U-Net architecture which showed good performance for the purpose of segmenting small objects on homogenous background. A U-Net model consists of two main parts: the downsampling (encoder) and upsampling (decoder) sections. The encoder is responsible for reducing the spatial dimensions of the input image while capturing essential features. This is achieved through a series of convolutional and pooling layers. These layers progressively process the image, extracting low-level and high-level features, thus condensing the information into a more compact representation. The decoder, on the other hand, takes the compact representation from the encoder and gradually upsamples it to match the original image's dimensions. The goal of the decoder is to reconstruct a segmented binary mask of the input image, where each pixel in the mask corresponds to a particular class or object of interest. This is achieved through a combination of transposed convolutional layers and skip connections, which allow the model to recover spatial details and maintain a contextual understanding of the image. To summarize, the encoder captures essential features thanks to convolutional layers, while the decoder reconstructs the image into a binary mask.

The employed U-Net model is structured with five layers, using maxpooling for downsampling, 'ReLU' activation layers to mitigate the vanishing gradient problem, ‘he_normal’ initialization for the kernels with a size of 2x2. Finally, a ‘Sigmoid’ activation layer is applied for the final output to map values between 0 and 1. For the loss function, we chose the native binary cross-entropy, and the optimizer used was Adam from the TensorFlow library. To mitigate the risk of overfitting, a dropout rate of 0.2 was introduced in the model, which helps prevent the neural network from relying too heavily on specific neurons during training. Batch normalization was disabled as experimental results indicated that it leads to a very slow convergence, probably due to the lack of sufficient number of positive class samples and the binary segmentation task. These hyperparameters were deliberately maintained consistently across all the different model variants. This decision simplifies the process of comparing and evaluating the performance of each model effectively. Then from this basic U-net several other U-net variants were built, incorporating different combinations (Attention Mechanisms, Multi-head Attention Mechanisms, Resnet, Resnext).

Features were chosen primarily based on visual inspection of ship appearances within the images (photo interpretation). Ultimately, all 10 meter resolution bands of Sentinel-2 were included (B02, B03, B04, B08), plus a NDWI single band, as it can be a good discriminator between water (background) and flooding objects (the positive class: ships).

Data augmentation was applied through rotations (90°, 180°, 270°) and flips (vertical, horizontal). Strong data augmentations such as cropping, brightness adjustment, saturation changes, or noise addition during training were not applied. This decision was made to ensure that the model relevant learns features to ship detection, as the final application does not involve noisy images.

To address class imbalance, only those patches containing at least five pixels belonging to ships were retained. Since ships represented the minority class in the binary masks, this threshold was crucial for effective model learning. From 16 images of 1783 x 938, after data augmentation and oversampling it results 3168 patches with a size of 64 x 64. This size was chosen, as ships could often be quite small objects, and the 64x64 patches allowed the model to capture relevant features without encountering the vanishing gradient effect.
